{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386b7e30-86f2-406e-8077-02abb26c35e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "from mlx.data import datasets\n",
    "import mlx.optimizers as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3132a89-2823-4425-a092-40284c6b783d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamed_data(data, batch_size=0, shuffled=True):\n",
    "    buffer = data.shuffle() if shuffled else data\n",
    "    stream = buffer.to_stream()\n",
    "    stream = stream.key_transform(\"image\", lambda x: x.astype(\"float32\"))\n",
    "    stream = stream.batch(batch_size) if batch_size > 0 else stream\n",
    "    return stream.prefetch(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d554b174-785c-463d-8db1-9d22cfeac888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training set\n",
    "\n",
    "mnist_train = datasets.load_mnist(train=True)\n",
    "mnist_test = datasets.load_mnist(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de4c0bd-9e2c-4139-a63e-f25cbc5cda87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 28, 28, 1), (1,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get one sample from the train set\n",
    "stream = get_streamed_data(mnist_train, batch_size=1, shuffled=False)\n",
    "batch = next(stream)\n",
    "X, y = mx.array(batch[\"image\"]), mx.array(batch[\"label\"])\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "079eae3c-0cc9-400f-8a20-0b0a353cef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 13, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create a convolution sequence\n",
    "conv_seq1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=1, kernel_size=2, stride=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2)\n",
    ")\n",
    "\n",
    "X_out1 = conv_seq1(X)\n",
    "print(X_out1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4be7a0c-beeb-4a94-b4b0-6f84b88d0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating output dimension of a Conv2d layer\n",
    "def get_convolution_output_dim(width, stride, kernel_size, padding):\n",
    "    \"\"\"\n",
    "    Assuming that the input image has dimension of width x width (square image).\n",
    "    We only need the width in this case\n",
    "    \"\"\" \n",
    "    return int(((width - kernel_size + (2 * padding)) / stride)) + 1\n",
    "\n",
    "def get_pooling_layer_out_dim(width, height, stride, kernel_size, padding):\n",
    "    \"\"\"\n",
    "    Assuming that stride and kernel is a square (e.g., 2x2)\n",
    "    \"\"\"\n",
    "    w_out = ((width + 2 * padding - kernel_size) / stride) + 1\n",
    "    h_out = ((height + 2 * padding - kernel_size) / stride) + 1\n",
    "    return int(w_out), int(h_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14775fb9-d0d6-47c2-b54c-635f150c42fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 13)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "# So long the convolution/pooling kernel size, padding, and stride is configurable\n",
    "# We can calculate each output dimension without passing a sample\n",
    "input_image_width = X.shape[-2]\n",
    "conv_padding = 0\n",
    "conv_stride = 1\n",
    "conv_kernel_size = 3\n",
    "\n",
    "pool_padding = 0\n",
    "pool_stride = 2\n",
    "pool_kernel_size = 2\n",
    "\n",
    "conv_seq_1_conv_out_dim = get_convolution_output_dim(input_image_width, conv_stride, conv_kernel_size, conv_padding)\n",
    "conv_seq_1_pooling_out_dim = get_pooling_layer_out_dim(\n",
    "    conv_seq_1_conv_out_dim,\n",
    "    conv_seq_1_conv_out_dim,\n",
    "    pool_stride,\n",
    "    pool_kernel_size,\n",
    "    pool_padding\n",
    ")\n",
    "\n",
    "print(conv_seq_1_pooling_out_dim)\n",
    "\n",
    "conv_seq_2_conv_out_dim = get_convolution_output_dim(\n",
    "    conv_seq_1_pooling_out_dim[-1],\n",
    "    conv_stride,\n",
    "    conv_kernel_size,\n",
    "    conv_padding\n",
    ")\n",
    "conv_seq_2_pooling_out_dim = get_pooling_layer_out_dim(\n",
    "    conv_seq_2_conv_out_dim,\n",
    "    conv_seq_2_conv_out_dim,\n",
    "    pool_stride,\n",
    "    pool_kernel_size,\n",
    "    pool_padding\n",
    ")\n",
    "\n",
    "print(conv_seq_2_pooling_out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57a3bace-cd4f-494b-a52d-24f8190a704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutedMNISTModel(nn.Module):\n",
    "    def __init__(self, input_channel, input_width, output_dims):\n",
    "        super().__init__()\n",
    "        conv2d_kernel_size = 3\n",
    "        conv2d_stride = 1\n",
    "        conv2d_padding = 0\n",
    "\n",
    "        pool2d_kernel_size = 2\n",
    "        pool2d_stride = 2\n",
    "        pool2d_padding = 0\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channel,\n",
    "                out_channels=input_channel,\n",
    "                kernel_size=conv2d_kernel_size,\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool2d_kernel_size, stride=pool2d_stride, padding=pool2d_padding),\n",
    "        )\n",
    "\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channel,\n",
    "                out_channels=input_channel,\n",
    "                kernel_size=conv2d_kernel_size,\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool2d_kernel_size, stride=pool2d_stride, padding=pool2d_padding),\n",
    "        )\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(input_dims=5*5*input_channel, output_dims=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dims=16, output_dims=16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dims=16, output_dims=output_dims),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        # print(f\"conv_layer1.out_shape -> {x.shape}\")\n",
    "        x = self.conv_layer2(x)\n",
    "        # print(f\"conv_layer2.out_shape -> {x.shape}\")\n",
    "        x = mx.flatten(x, start_axis=1) # ignore the batch shape (axis=0)\n",
    "        # print(f\"mx.flatten.out_shape -> {x.shape}\")\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c51e8a27-cc20-49ec-aaa4-26c32b87d4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvolutedMNISTModel(\n",
       "  (conv_layer1): Sequential(\n",
       "    (layers.0): Conv2d(1, 1, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  )\n",
       "  (conv_layer2): Sequential(\n",
       "    (layers.0): Conv2d(1, 1, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  )\n",
       "  (fully_connected): Sequential(\n",
       "    (layers.0): Linear(input_dims=25, output_dims=16, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): Linear(input_dims=16, output_dims=16, bias=True)\n",
       "    (layers.3): ReLU()\n",
       "    (layers.4): Linear(input_dims=16, output_dims=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = 10 # number of classes\n",
    "INPUT_WIDTH = 28 # image width -> assuming a square image\n",
    "INPUT_CHANNEL = 1 # 1 color  channel\n",
    "\n",
    "model = ConvolutedMNISTModel(\n",
    "    input_channel=INPUT_CHANNEL,\n",
    "    input_width=INPUT_WIDTH,\n",
    "    output_dims=NUM_CLASSES\n",
    ")\n",
    "\n",
    "mx.eval(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d70e68a-8f8f-4b19-84d6-16eb8c184506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    return nn.losses.cross_entropy(logits, y, reduction=\"mean\")\n",
    "\n",
    "def eval_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    pred = nn.softmax(logits)\n",
    "    return mx.mean(mx.argmax(pred, axis=1) == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394299d2-00c5-40ac-8a03-684afba146e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 1.9087590671600179, Train Accuracy: 0.2977670656873825 | Test Accuracy: 0.6873003194888179\n",
      "Epoch: 1 | Train Loss: 0.685671506283131, Train Accuracy: 0.804471409574468 | Test Accuracy: 0.8404552715654952\n",
      "Epoch: 2 | Train Loss: 0.4817481907124215, Train Accuracy: 0.8681959220703612 | Test Accuracy: 0.8607228434504792\n",
      "Epoch: 3 | Train Loss: 0.4174379700041832, Train Accuracy: 0.886846188027808 | Test Accuracy: 0.8851837060702875\n",
      "Epoch: 4 | Train Loss: 0.3890635477735641, Train Accuracy: 0.8958111702127659 | Test Accuracy: 0.8976637380191693\n",
      "Epoch: 5 | Train Loss: 0.3685422419233525, Train Accuracy: 0.9015403369639782 | Test Accuracy: 0.8973642172523961\n",
      "Epoch: 6 | Train Loss: 0.3554524838924408, Train Accuracy: 0.9047872340425532 | Test Accuracy: 0.9034544728434505\n",
      "Epoch: 7 | Train Loss: 0.3467174992916432, Train Accuracy: 0.9068816489361702 | Test Accuracy: 0.9095447284345048\n",
      "Epoch: 8 | Train Loss: 0.3388098003382378, Train Accuracy: 0.9091866135597229 | Test Accuracy: 0.8995607028753994\n",
      "Epoch: 9 | Train Loss: 0.3339494754025277, Train Accuracy: 0.9099512412192974 | Test Accuracy: 0.9092452076677316\n",
      "Epoch: 10 | Train Loss: 0.3284338893408471, Train Accuracy: 0.9126163563829788 | Test Accuracy: 0.9048522364217252\n",
      "Epoch: 11 | Train Loss: 0.32195591210050784, Train Accuracy: 0.9125110816448293 | Test Accuracy: 0.8830870607028753\n",
      "Epoch: 12 | Train Loss: 0.32056660785319957, Train Accuracy: 0.9142675090343394 | Test Accuracy: 0.9105431309904153\n",
      "Epoch: 13 | Train Loss: 0.3165147355896361, Train Accuracy: 0.9139295212765958 | Test Accuracy: 0.9121405750798722\n",
      "Epoch: 14 | Train Loss: 0.31508071834736684, Train Accuracy: 0.9151595744680852 | Test Accuracy: 0.9091453674121406\n",
      "Epoch: 15 | Train Loss: 0.3115236001445892, Train Accuracy: 0.9149601063829788 | Test Accuracy: 0.9017571884984026\n",
      "Epoch: 16 | Train Loss: 0.3070997441702701, Train Accuracy: 0.9164284132896585 | Test Accuracy: 0.9161341853035144\n",
      "Epoch: 17 | Train Loss: 0.3054688735211149, Train Accuracy: 0.9167331561129144 | Test Accuracy: 0.9130391373801917\n",
      "Epoch: 18 | Train Loss: 0.30528124589869315, Train Accuracy: 0.9175753547790203 | Test Accuracy: 0.9158346645367412\n",
      "Epoch: 19 | Train Loss: 0.30189584316091334, Train Accuracy: 0.9180075356300841 | Test Accuracy: 0.911741214057508\n",
      "Epoch: 20 | Train Loss: 0.29833007359758335, Train Accuracy: 0.9178191489361702 | Test Accuracy: 0.9034544728434505\n",
      "Epoch: 21 | Train Loss: 0.2977578913277768, Train Accuracy: 0.9190104167512123 | Test Accuracy: 0.9159345047923323\n",
      "Epoch: 22 | Train Loss: 0.29667594686467597, Train Accuracy: 0.919536790949233 | Test Accuracy: 0.9009584664536742\n",
      "Epoch: 23 | Train Loss: 0.29343009457943287, Train Accuracy: 0.9205230497299357 | Test Accuracy: 0.9166333865814696\n",
      "Epoch: 24 | Train Loss: 0.2922996613573521, Train Accuracy: 0.9204177749917862 | Test Accuracy: 0.9092452076677316\n",
      "Epoch: 25 | Train Loss: 0.2899877116401145, Train Accuracy: 0.9202903369639782 | Test Accuracy: 0.9187300319488818\n",
      "Epoch: 26 | Train Loss: 0.2900397059765268, Train Accuracy: 0.9202737146235527 | Test Accuracy: 0.9157348242811502\n",
      "Epoch: 27 | Train Loss: 0.28799729810116137, Train Accuracy: 0.9218916223404255 | Test Accuracy: 0.9150359424920128\n",
      "Epoch: 28 | Train Loss: 0.28628332158352465, Train Accuracy: 0.9212876773895101 | Test Accuracy: 0.908047124600639\n",
      "Epoch: 29 | Train Loss: 0.2855795053091455, Train Accuracy: 0.9213929521276596 | Test Accuracy: 0.8994608626198083\n",
      "Epoch: 30 | Train Loss: 0.2844884493249528, Train Accuracy: 0.9221797430768927 | Test Accuracy: 0.9137380191693291\n",
      "Epoch: 31 | Train Loss: 0.2822884558363164, Train Accuracy: 0.9223127218002969 | Test Accuracy: 0.9203274760383386\n",
      "Epoch: 32 | Train Loss: 0.2810946458831747, Train Accuracy: 0.9224457005237011 | Test Accuracy: 0.9160343450479234\n",
      "Epoch: 33 | Train Loss: 0.28215595325256915, Train Accuracy: 0.922345966481148 | Test Accuracy: 0.919129392971246\n",
      "Epoch: 34 | Train Loss: 0.2802331745624542, Train Accuracy: 0.9233322252618505 | Test Accuracy: 0.9188298722044729\n",
      "Epoch: 35 | Train Loss: 0.2784297007829585, Train Accuracy: 0.9230939718002968 | Test Accuracy: 0.9188298722044729\n",
      "Epoch: 36 | Train Loss: 0.2778129549736672, Train Accuracy: 0.9228113920130628 | Test Accuracy: 0.9077476038338658\n",
      "Epoch: 37 | Train Loss: 0.27666007426190886, Train Accuracy: 0.9235926420130628 | Test Accuracy: 0.9160343450479234\n",
      "Epoch: 38 | Train Loss: 0.27642786312610546, Train Accuracy: 0.9236425090343394 | Test Accuracy: 0.9184305111821086\n",
      "Epoch: 39 | Train Loss: 0.275315978298796, Train Accuracy: 0.9251274380278081 | Test Accuracy: 0.9214257188498403\n",
      "Epoch: 40 | Train Loss: 0.27434410960116284, Train Accuracy: 0.923033023134191 | Test Accuracy: 0.9211261980830671\n",
      "Epoch: 41 | Train Loss: 0.27317316639930644, Train Accuracy: 0.925249335106383 | Test Accuracy: 0.9206269968051118\n",
      "Epoch: 42 | Train Loss: 0.27153402814205657, Train Accuracy: 0.9256316489361702 | Test Accuracy: 0.9196285942492013\n",
      "Epoch: 43 | Train Loss: 0.27327606601918, Train Accuracy: 0.9244902483960415 | Test Accuracy: 0.9237220447284346\n",
      "Epoch: 44 | Train Loss: 0.2714301964704027, Train Accuracy: 0.9256150265957447 | Test Accuracy: 0.919029552715655\n",
      "Epoch: 45 | Train Loss: 0.2715203984620723, Train Accuracy: 0.925282579787234 | Test Accuracy: 0.9126397763578274\n",
      "Epoch: 46 | Train Loss: 0.26976907126446986, Train Accuracy: 0.9258976063829787 | Test Accuracy: 0.9219249201277955\n",
      "Epoch: 47 | Train Loss: 0.26943170130252836, Train Accuracy: 0.9265070922831271 | Test Accuracy: 0.922823482428115\n"
     ]
    }
   ],
   "source": [
    "# Start training loop\n",
    "\n",
    "epochs = 50\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "optimizer = optim.SGD(learning_rate=0.01)\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    epoch_counter = 0\n",
    "    for batch in get_streamed_data(mnist_train, batch_size=256, shuffled=True):\n",
    "        X, y = batch[\"image\"], batch[\"label\"]\n",
    "        # Need to convert X and y into mlx.core.array type\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        # Compute loss and its gradient with respect to the model's trainable parameters\n",
    "        loss, grad = loss_and_grad_fn(model, X, y)\n",
    "        # Step the optimizer\n",
    "        optimizer.update(model, grad)\n",
    "        # Evaluate computational graph\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_counter += 1\n",
    "        train_acc += eval_fn(model, X, y).item()\n",
    "    epoch_loss /= epoch_counter\n",
    "    train_acc /= epoch_counter\n",
    "\n",
    "    test_acc_counter = 0.0\n",
    "    test_acc = 0.0\n",
    "    for batch in get_streamed_data(mnist_test, batch_size=32, shuffled=False):\n",
    "        X, y = batch[\"image\"], batch[\"label\"]\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        acc = eval_fn(model, X, y)\n",
    "        test_acc += acc.item()\n",
    "        test_acc_counter += 1\n",
    "    test_acc /= test_acc_counter\n",
    "    print(f\"Epoch: {epoch} | Train Loss: {epoch_loss}, Train Accuracy: {train_acc} | Test Accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055cd077-85bc-4bf9-9aaf-1b296ac7652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing out with one random sample\n",
    "test_stream = get_streamed_data(mnist_test, batch_size=1)\n",
    "test_batch = next(test_stream)\n",
    "X, y = mx.array(test_batch[\"image\"]), mx.array(test_batch[\"label\"])\n",
    "\n",
    "# See how the model produce logits\n",
    "logits = model(X)\n",
    "print(f\"Logits: {logits}\")\n",
    "\n",
    "# See we can compute the softmax from the logits\n",
    "softmax = nn.softmax(logits)\n",
    "print(f\"Softmax-ed: {softmax}\")\n",
    "\n",
    "# Get predicted label and true label\n",
    "predicted_label = mx.argmax(softmax, axis=1).item()\n",
    "confidence_level = mx.max(softmax, axis=1).item()\n",
    "print(f\"Predicted label: {predicted_label}, True label: {y.item()} | Confidence level: {confidence_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6269604-bd5a-42eb-84d2-7fb039f8f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get precision, recall, and f1-score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for batch in get_streamed_data(mnist_test, batch_size=32, shuffled=False):\n",
    "    X, y = batch[\"image\"], batch[\"label\"]\n",
    "    X, y = mx.array(X), mx.array(y)\n",
    "    logits = model(X)\n",
    "    prediction = mx.argmax(mx.softmax(logits), axis=1)\n",
    "    y_true = y_true + y.tolist()\n",
    "    y_pred = y_pred + prediction.tolist()\n",
    "    \n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc39cb1-2ea0-4b47-a2f1-65f5834f50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "display = ConfusionMatrixDisplay(conf_matrix)\n",
    "display.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116aefaf-8ece-4879-ab41-ef3c14818d41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
