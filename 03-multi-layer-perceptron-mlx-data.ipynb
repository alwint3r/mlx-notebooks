{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a194b79-d4b7-4dda-8982-441316198888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import mlx.optimizers as optim\n",
    "from mlx.data.datasets import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735099ed-3182-4e90-a47c-af0429f92ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "# If not exists, the mlx.data package will download\n",
    "# the dataset into your local directory\n",
    "# you can provide `root` arguments to set the destination\n",
    "mnist_train = load_mnist(train=True)\n",
    "mnist_test = load_mnist(train=False)\n",
    "\n",
    "len(mnist_train), len(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bddc409d-ed2f-4481-a9da-ea9084c3b3f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((32, 784), (32,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_streamed_data(data, batch_size=32, shuffled=True):\n",
    "    buffer = data.shuffle() if shuffled else data\n",
    "    return (buffer\n",
    "            .to_stream()\n",
    "            .key_transform(\"image\", lambda x: x.astype(\"float32\").reshape(-1,))\n",
    "            .batch(batch_size)\n",
    "            .prefetch(4, 2)\n",
    "    )\n",
    "\n",
    "mnist_trainstream = get_streamed_data(mnist_train)\n",
    "\n",
    "## Without .reshape(-1,), the shape of the batch is (32, 28, 28, 1)\n",
    "## With .reshape(-1,) the shape of the batch is (32, 784) -> easier to handle with fully-connected layer\n",
    "\n",
    "# Uncomment below lines to see the shape\n",
    "first_batch = next(mnist_trainstream)\n",
    "X, y = first_batch[\"image\"], first_batch[\"label\"]\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32c719a-5591-41e6-8097-95ae12535c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (sequential): Sequential(\n",
       "    (layers.0): Linear(input_dims=784, output_dims=64, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): Linear(input_dims=64, output_dims=64, bias=True)\n",
       "    (layers.3): ReLU()\n",
       "    (layers.4): Linear(input_dims=64, output_dims=64, bias=True)\n",
       "    (layers.5): ReLU()\n",
       "    (layers.6): Linear(input_dims=64, output_dims=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dims, hidden_dims, output_dims):\n",
    "        super().__init__()\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Linear(input_dims=input_dims, output_dims=hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dims=hidden_dims, output_dims=hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dims=hidden_dims, output_dims=hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dims=hidden_dims, output_dims=output_dims)\n",
    "        )\n",
    "    def __call__(self, x):\n",
    "        return self.sequential(x)\n",
    "\n",
    "model = MLP(input_dims=784, hidden_dims=64, output_dims=10)\n",
    "mx.eval(model.parameters())\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcedfadf-ddf6-434d-a3f7-1dbaa3a65b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    return nn.losses.cross_entropy(logits, y, reduction=\"mean\")\n",
    "\n",
    "def eval_fn(model, X, y):\n",
    "    logits = model(X)\n",
    "    pred = nn.softmax(logits)\n",
    "    return mx.mean(mx.argmax(pred, axis=1) == y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b632851-1f68-4add-a2e7-30ab18269f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train Loss: 0.47950050482090484, Train Accuracy: 0.8891788563829788 | Test Accuracy: 0.9236222044728435\n",
      "Epoch: 1 | Train Loss: 0.1966099038403085, Train Accuracy: 0.9639572252618506 | Test Accuracy: 0.9353035143769968\n",
      "Epoch: 2 | Train Loss: 0.1525057036508905, Train Accuracy: 0.9753379877577437 | Test Accuracy: 0.9518769968051118\n",
      "Epoch: 3 | Train Loss: 0.13113700432029177, Train Accuracy: 0.980474290949233 | Test Accuracy: 0.9060503194888179\n",
      "Epoch: 4 | Train Loss: 0.11118966062018212, Train Accuracy: 0.9848404255319149 | Test Accuracy: 0.9563698083067093\n",
      "Epoch: 5 | Train Loss: 0.09633462732618159, Train Accuracy: 0.9876218973322117 | Test Accuracy: 0.9616613418530351\n",
      "Epoch: 6 | Train Loss: 0.08666957761854567, Train Accuracy: 0.9899268617021276 | Test Accuracy: 0.9544728434504792\n",
      "Epoch: 7 | Train Loss: 0.07647806671547129, Train Accuracy: 0.9918882978723405 | Test Accuracy: 0.9634584664536742\n",
      "Epoch: 8 | Train Loss: 0.06889768651825316, Train Accuracy: 0.9930186170212766 | Test Accuracy: 0.9653554313099042\n",
      "Epoch: 9 | Train Loss: 0.06387119583309965, Train Accuracy: 0.9945146276595744 | Test Accuracy: 0.9647563897763578\n",
      "Epoch: 10 | Train Loss: 0.05782506769483394, Train Accuracy: 0.9951961436170212 | Test Accuracy: 0.9642571884984026\n",
      "Epoch: 11 | Train Loss: 0.053021327338795714, Train Accuracy: 0.9959109042553191 | Test Accuracy: 0.9681509584664537\n",
      "Epoch: 12 | Train Loss: 0.04880148179512075, Train Accuracy: 0.996597961161999 | Test Accuracy: 0.9653554313099042\n",
      "Epoch: 13 | Train Loss: 0.04554958936778155, Train Accuracy: 0.9970467643534884 | Test Accuracy: 0.9574680511182109\n",
      "Epoch: 14 | Train Loss: 0.0431693665128439, Train Accuracy: 0.9973570478723405 | Test Accuracy: 0.9670527156549521\n",
      "Epoch: 15 | Train Loss: 0.03796664132399762, Train Accuracy: 0.9979886968085107 | Test Accuracy: 0.9691493610223643\n",
      "Epoch: 16 | Train Loss: 0.03358768310318602, Train Accuracy: 0.9983543882978724 | Test Accuracy: 0.9673522364217252\n",
      "Epoch: 17 | Train Loss: 0.03241625981048701, Train Accuracy: 0.9981382978723404 | Test Accuracy: 0.9677515974440895\n",
      "Epoch: 18 | Train Loss: 0.029820945371497185, Train Accuracy: 0.9984208776595744 | Test Accuracy: 0.9685503194888179\n",
      "Epoch: 19 | Train Loss: 0.02604679101483619, Train Accuracy: 0.9989195478723404 | Test Accuracy: 0.9681509584664537\n",
      "Epoch: 20 | Train Loss: 0.024047586628969046, Train Accuracy: 0.9990525265957447 | Test Accuracy: 0.9699480830670927\n",
      "Epoch: 21 | Train Loss: 0.021484294569397225, Train Accuracy: 0.9990525265957447 | Test Accuracy: 0.9694488817891374\n",
      "Epoch: 22 | Train Loss: 0.021094332996042485, Train Accuracy: 0.9991411792471053 | Test Accuracy: 0.9367012779552716\n",
      "Epoch: 23 | Train Loss: 0.021027585249790485, Train Accuracy: 0.9989195478723404 | Test Accuracy: 0.9686501597444089\n",
      "Epoch: 24 | Train Loss: 0.01688042742378534, Train Accuracy: 0.9993517287234043 | Test Accuracy: 0.9679512779552716\n",
      "Epoch: 25 | Train Loss: 0.05925803077902565, Train Accuracy: 0.9945811170212766 | Test Accuracy: 0.9707468051118211\n",
      "Epoch: 26 | Train Loss: 0.01566224505213347, Train Accuracy: 0.9994514627659574 | Test Accuracy: 0.9715455271565495\n",
      "Epoch: 27 | Train Loss: 0.013542261446251515, Train Accuracy: 0.9995179521276596 | Test Accuracy: 0.9713458466453674\n",
      "Epoch: 28 | Train Loss: 0.012727083832501098, Train Accuracy: 0.9996176861702127 | Test Accuracy: 0.9717452076677316\n",
      "Epoch: 29 | Train Loss: 0.010648002015783432, Train Accuracy: 0.999750664893617 | Test Accuracy: 0.9703474440894568\n",
      "Epoch: 30 | Train Loss: 0.009282118632913904, Train Accuracy: 0.9998393175449777 | Test Accuracy: 0.970547124600639\n",
      "Epoch: 31 | Train Loss: 0.008662562424990725, Train Accuracy: 0.9998171542553191 | Test Accuracy: 0.9712460063897763\n",
      "Epoch: 32 | Train Loss: 0.008282058987211674, Train Accuracy: 0.999783909574468 | Test Accuracy: 0.9711461661341853\n",
      "Epoch: 33 | Train Loss: 0.007073024057961525, Train Accuracy: 0.9998836436170213 | Test Accuracy: 0.9710463258785943\n",
      "Epoch: 34 | Train Loss: 0.006119647782612988, Train Accuracy: 0.9999335106382978 | Test Accuracy: 0.9718450479233227\n",
      "Epoch: 35 | Train Loss: 0.0058798142015299894, Train Accuracy: 0.9999168882978723 | Test Accuracy: 0.9682507987220448\n",
      "Epoch: 36 | Train Loss: 0.0050885297734528144, Train Accuracy: 0.9999501329787234 | Test Accuracy: 0.9704472843450479\n",
      "Epoch: 37 | Train Loss: 0.004600202314000814, Train Accuracy: 0.9999501329787234 | Test Accuracy: 0.9719448881789138\n",
      "Epoch: 38 | Train Loss: 0.004065272805498952, Train Accuracy: 0.9999335106382978 | Test Accuracy: 0.9712460063897763\n",
      "Epoch: 39 | Train Loss: 0.0037724319052823045, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9717452076677316\n",
      "Epoch: 40 | Train Loss: 0.0033541969811306037, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9720447284345048\n",
      "Epoch: 41 | Train Loss: 0.003101212796854212, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9719448881789138\n",
      "Epoch: 42 | Train Loss: 0.002733661644557055, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9719448881789138\n",
      "Epoch: 43 | Train Loss: 0.0025519204345789363, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9719448881789138\n",
      "Epoch: 44 | Train Loss: 0.0023886500203863102, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9712460063897763\n",
      "Epoch: 45 | Train Loss: 0.002201388462228661, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9725439297124601\n",
      "Epoch: 46 | Train Loss: 0.002000776106402516, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9718450479233227\n",
      "Epoch: 47 | Train Loss: 0.001828478863264652, Train Accuracy: 0.9999833776595745 | Test Accuracy: 0.9711461661341853\n",
      "Epoch: 48 | Train Loss: 0.0018110237777867217, Train Accuracy: 1.0 | Test Accuracy: 0.9710463258785943\n",
      "Epoch: 49 | Train Loss: 0.001667703854593825, Train Accuracy: 1.0 | Test Accuracy: 0.9722444089456869\n"
     ]
    }
   ],
   "source": [
    "# Start training loop\n",
    "\n",
    "epochs = 50\n",
    "loss_and_grad_fn = nn.value_and_grad(model, loss_fn)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(learning_rate=0.01)\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    epoch_counter = 0\n",
    "    for batch in get_streamed_data(mnist_train, batch_size=256):\n",
    "        X, y = batch[\"image\"], batch[\"label\"]\n",
    "        # Need to convert X and y into mlx.core.array type\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        # Compute loss and its gradient with respect to the model's trainable parameters\n",
    "        loss, grad = loss_and_grad_fn(model, X, y)\n",
    "        # Step the optimizer\n",
    "        optimizer.update(model, grad)\n",
    "        # Evaluate computational graph\n",
    "        mx.eval(model.parameters(), optimizer.state)\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_counter += 1\n",
    "        train_acc += eval_fn(model, X, y).item()\n",
    "    epoch_loss /= epoch_counter\n",
    "    train_acc /= epoch_counter\n",
    "\n",
    "    test_acc_counter = 0.0\n",
    "    test_acc = 0.0\n",
    "    for batch in get_streamed_data(mnist_test, batch_size=32, shuffled=False):\n",
    "        X, y = batch[\"image\"], batch[\"label\"]\n",
    "        X, y = mx.array(X), mx.array(y)\n",
    "        acc = eval_fn(model, X, y)\n",
    "        test_acc += acc.item()\n",
    "        test_acc_counter += 1\n",
    "    test_acc /= test_acc_counter\n",
    "    print(f\"Epoch: {epoch} | Train Loss: {epoch_loss}, Train Accuracy: {train_acc} | Test Accuracy: {test_acc}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8962b18-b785-4f27-aa02-31004b55a135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits: array([[-1.13314, 0.136331, 1.44552, ..., -5.11404, 25.6358, -0.246675]], dtype=float32)\n",
      "Softmax-ed: array([[2.36799e-12, 8.42763e-12, 3.1209e-11, ..., 4.42079e-14, 1, 5.74603e-12]], dtype=float32)\n",
      "Predicted label: 8, True label: 8 | Confidence level: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Testing out with one random sample\n",
    "test_stream = get_streamed_data(mnist_test, batch_size=1)\n",
    "test_batch = next(test_stream)\n",
    "X, y = mx.array(test_batch[\"image\"]), mx.array(test_batch[\"label\"])\n",
    "\n",
    "# See how the model produce logits\n",
    "logits = model(X)\n",
    "print(f\"Logits: {logits}\")\n",
    "\n",
    "# See we can compute the softmax from the logits\n",
    "softmax = nn.softmax(logits)\n",
    "print(f\"Softmax-ed: {softmax}\")\n",
    "\n",
    "# Get predicted label and true label\n",
    "predicted_label = mx.argmax(softmax, axis=1).item()\n",
    "confidence_level = mx.max(softmax, axis=1).item()\n",
    "print(f\"Predicted label: {predicted_label}, True label: {y.item()} | Confidence level: {confidence_level}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b243ba62-9932-421b-9359-cf87f19d2b83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
