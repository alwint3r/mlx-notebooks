{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae071b23-1f32-416c-8d76-6ce501567305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import numpy as np\n",
    "from mlx.data import datasets\n",
    "from datasets_utils import cifar100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e93704da-be13-45c5-af7e-6f54b85471ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streamed_data(data, batch_size=0, shuffled=True):\n",
    "    def transform_image(x):\n",
    "        return x.astype(\"float32\") / 255.0\n",
    "\n",
    "    buffer = data.shuffle() if shuffled else data\n",
    "    stream = buffer.to_stream()\n",
    "    stream = stream.key_transform(\"image\", transform_image)\n",
    "    stream = stream.batch(batch_size) if batch_size > 0 else stream\n",
    "    return stream.prefetch(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7804b452-c360-42e8-8303-7dda46a0e7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.load_cifar100(train=True)\n",
    "test_data = datasets.load_cifar100(train=False)\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5506e2e-3e70-4021-acb0-0957f14aa45a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition length: 10000\n",
      "Batch image shape: (1, 32, 32, 3)\n",
      "Batch label shape: (1,)\n",
      "Original data length: 50000\n"
     ]
    }
   ],
   "source": [
    "# partition train_data into 5 partitions and return the first partition (index 0)\n",
    "partitioned = train_data.partition(5, 0)\n",
    "print(f\"Partition length: {len(partitioned)}\")\n",
    "\n",
    "streamed_partition = get_streamed_data(partitioned, batch_size=1, shuffled=True)\n",
    "batch = next(streamed_partition)\n",
    "print(f\"Batch image shape: {batch['image'].shape}\\nBatch label shape: {batch['label'].shape}\")\n",
    "print(f\"Original data length: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b78a14-388d-4b31-9a23-9dc8ed4a444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_channel, input_width, conv_filters, output_dims):\n",
    "        super().__init__()\n",
    "        conv2d_kernel_size = 3\n",
    "        conv2d_stride = 1\n",
    "        conv2d_padding = 0\n",
    "\n",
    "        pool2d_kernel_size = 2\n",
    "        pool2d_stride = 2\n",
    "        pool2d_padding = 0\n",
    "\n",
    "        self.conv_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_channel,\n",
    "                out_channels=conv_filters,\n",
    "                kernel_size=(conv2d_kernel_size, conv2d_kernel_size),\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=conv_filters,\n",
    "                out_channels=conv_filters,\n",
    "                kernel_size=(conv2d_kernel_size, conv2d_kernel_size),\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool2d_kernel_size, stride=pool2d_stride, padding=pool2d_padding),\n",
    "        )\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm(conv_filters)\n",
    "\n",
    "        self.conv_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=conv_filters,\n",
    "                out_channels=conv_filters,\n",
    "                kernel_size=(conv2d_kernel_size, conv2d_kernel_size),\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=conv_filters,\n",
    "                out_channels=conv_filters,\n",
    "                kernel_size=(conv2d_kernel_size, conv2d_kernel_size),\n",
    "                stride=conv2d_stride,\n",
    "                padding=conv2d_padding\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=pool2d_kernel_size, stride=pool2d_stride, padding=pool2d_padding),\n",
    "        )\n",
    "\n",
    "        self.batch_norm2 = nn.BatchNorm(conv_filters)\n",
    "\n",
    "        self.fully_connected = nn.Sequential(\n",
    "            nn.Linear(input_dims=5*5*conv_filters, output_dims=output_dims),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.conv_layer1(x)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.conv_layer2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = mx.flatten(x, start_axis=1, end_axis=-1)\n",
    "        x = self.fully_connected(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1592fd05-0e65-426e-825e-3a53ecebc61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (conv_layer1): Sequential(\n",
       "    (layers.0): Conv2d(3, 128, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): Conv2d(128, 128, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.3): ReLU()\n",
       "    (layers.4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  )\n",
       "  (batch_norm1): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv_layer2): Sequential(\n",
       "    (layers.0): Conv2d(128, 128, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.1): ReLU()\n",
       "    (layers.2): Conv2d(128, 128, kernel_size=(3,), stride=(1, 1), padding=(0, 0), dilation=1, bias=True)\n",
       "    (layers.3): ReLU()\n",
       "    (layers.4): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  )\n",
       "  (batch_norm2): BatchNorm(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fully_connected): Sequential(\n",
       "    (layers.0): Linear(input_dims=3200, output_dims=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_CLASSES = len(cifar100.labels)\n",
    "INPUT_WIDTH = 32\n",
    "INPUT_CHANNEL = 3\n",
    "CONV_FILTERS = 128\n",
    "\n",
    "model = Model(\n",
    "    input_channel=INPUT_CHANNEL,\n",
    "    input_width=INPUT_WIDTH,\n",
    "    conv_filters=CONV_FILTERS,\n",
    "    output_dims=NUM_CLASSES\n",
    ")\n",
    "\n",
    "mx.eval(model)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19a4e7f4-5bb8-4003-964f-742db2476aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Partition: 0 | Score: 0.1699923723936081\n",
      "Epoch: 1 | Partition: 1 | Score: 0.2138671875\n",
      "Epoch: 1 | Partition: 2 | Score: 0.25708451867103577\n",
      "Epoch: 1 | Partition: 3 | Score: 0.2903042733669281\n",
      "Epoch: 1 | Partition: 4 | Score: 0.32500001788139343\n",
      "Epoch: 1 | avg. Train loss 4.410 | avg. Train acc 0.227 | Throughput: 1370.69 images/sec\n",
      "Epoch: 2 | Partition: 0 | Score: 0.3428710997104645\n",
      "Epoch: 2 | Partition: 1 | Score: 0.3623046875\n",
      "Epoch: 2 | Partition: 2 | Score: 0.38398438692092896\n",
      "Epoch: 2 | Partition: 3 | Score: 0.4040471613407135\n",
      "Epoch: 2 | Partition: 4 | Score: 0.43463611602783203\n",
      "Epoch: 2 | avg. Train loss 4.273 | avg. Train acc 0.378 | Throughput: 1371.07 images/sec\n",
      "Epoch: 3 | Partition: 0 | Score: 0.4432617127895355\n",
      "Epoch: 3 | Partition: 1 | Score: 0.46004238724708557\n",
      "Epoch: 3 | Partition: 2 | Score: 0.482614666223526\n",
      "Epoch: 3 | Partition: 3 | Score: 0.5029004216194153\n",
      "Epoch: 3 | Partition: 4 | Score: 0.5239062309265137\n",
      "Epoch: 3 | avg. Train loss 4.180 | avg. Train acc 0.476 | Throughput: 1354.73 images/sec\n",
      "Epoch: 4 | Partition: 0 | Score: 0.5253559947013855\n",
      "Epoch: 4 | Partition: 1 | Score: 0.540332019329071\n",
      "Epoch: 4 | Partition: 2 | Score: 0.5501519441604614\n",
      "Epoch: 4 | Partition: 3 | Score: 0.5721679925918579\n",
      "Epoch: 4 | Partition: 4 | Score: 0.5908026099205017\n",
      "Epoch: 4 | avg. Train loss 4.107 | avg. Train acc 0.549 | Throughput: 1366.15 images/sec\n",
      "Epoch: 5 | Partition: 0 | Score: 0.5882275700569153\n",
      "Epoch: 5 | Partition: 1 | Score: 0.5957832932472229\n",
      "Epoch: 5 | Partition: 2 | Score: 0.6094531416893005\n",
      "Epoch: 5 | Partition: 3 | Score: 0.623339831829071\n",
      "Epoch: 5 | Partition: 4 | Score: 0.6320282816886902\n",
      "Epoch: 5 | avg. Train loss 4.050 | avg. Train acc 0.604 | Throughput: 1377.31 images/sec\n",
      "Epoch: 6 | Partition: 0 | Score: 0.6351026892662048\n",
      "Epoch: 6 | Partition: 1 | Score: 0.6370381116867065\n",
      "Epoch: 6 | Partition: 2 | Score: 0.6476573348045349\n",
      "Epoch: 6 | Partition: 3 | Score: 0.6663950681686401\n",
      "Epoch: 6 | Partition: 4 | Score: 0.6691034436225891\n",
      "Epoch: 6 | avg. Train loss 4.004 | avg. Train acc 0.646 | Throughput: 1359.76 images/sec\n",
      "Epoch: 7 | Partition: 0 | Score: 0.6719689965248108\n",
      "Epoch: 7 | Partition: 1 | Score: 0.678515613079071\n",
      "Epoch: 7 | Partition: 2 | Score: 0.6841136813163757\n",
      "Epoch: 7 | Partition: 3 | Score: 0.6917968988418579\n",
      "Epoch: 7 | Partition: 4 | Score: 0.701367199420929\n",
      "Epoch: 7 | avg. Train loss 3.963 | avg. Train acc 0.682 | Throughput: 1357.34 images/sec\n",
      "Epoch: 8 | Partition: 0 | Score: 0.69921875\n",
      "Epoch: 8 | Partition: 1 | Score: 0.7114982008934021\n",
      "Epoch: 8 | Partition: 2 | Score: 0.7100586295127869\n",
      "Epoch: 8 | Partition: 3 | Score: 0.7198242545127869\n",
      "Epoch: 8 | Partition: 4 | Score: 0.7324166297912598\n",
      "Epoch: 8 | avg. Train loss 3.932 | avg. Train acc 0.710 | Throughput: 1367.25 images/sec\n",
      "Epoch: 9 | Partition: 0 | Score: 0.718554675579071\n",
      "Epoch: 9 | Partition: 1 | Score: 0.7204820513725281\n",
      "Epoch: 9 | Partition: 2 | Score: 0.7430071234703064\n",
      "Epoch: 9 | Partition: 3 | Score: 0.7451171875\n",
      "Epoch: 9 | Partition: 4 | Score: 0.7471680045127869\n",
      "Epoch: 9 | avg. Train loss 3.904 | avg. Train acc 0.733 | Throughput: 1353.43 images/sec\n",
      "Epoch: 10 | Partition: 0 | Score: 0.7476562857627869\n",
      "Epoch: 10 | Partition: 1 | Score: 0.7528469562530518\n",
      "Epoch: 10 | Partition: 2 | Score: 0.745898425579071\n",
      "Epoch: 10 | Partition: 3 | Score: 0.7573065161705017\n",
      "Epoch: 10 | Partition: 4 | Score: 0.76513671875\n",
      "Epoch: 10 | avg. Train loss 3.887 | avg. Train acc 0.749 | Throughput: 1352.30 images/sec\n",
      "Epoch: 11 | Partition: 0 | Score: 0.7520508170127869\n",
      "Epoch: 11 | Partition: 1 | Score: 0.7531391382217407\n",
      "Epoch: 11 | Partition: 2 | Score: 0.7641379237174988\n",
      "Epoch: 11 | Partition: 3 | Score: 0.77197265625\n",
      "Epoch: 11 | Partition: 4 | Score: 0.7757812738418579\n",
      "Epoch: 11 | avg. Train loss 3.869 | avg. Train acc 0.764 | Throughput: 1342.18 images/sec\n",
      "Epoch: 12 | Partition: 0 | Score: 0.7782953381538391\n",
      "Epoch: 12 | Partition: 1 | Score: 0.7760677337646484\n",
      "Epoch: 12 | Partition: 2 | Score: 0.778124988079071\n",
      "Epoch: 12 | Partition: 3 | Score: 0.783880889415741\n",
      "Epoch: 12 | Partition: 4 | Score: 0.7806640863418579\n",
      "Epoch: 12 | avg. Train loss 3.852 | avg. Train acc 0.779 | Throughput: 1356.44 images/sec\n",
      "Epoch: 13 | Partition: 0 | Score: 0.7867187857627869\n",
      "Epoch: 13 | Partition: 1 | Score: 0.787402331829071\n",
      "Epoch: 13 | Partition: 2 | Score: 0.7997070550918579\n",
      "Epoch: 13 | Partition: 3 | Score: 0.7908416986465454\n",
      "Epoch: 13 | Partition: 4 | Score: 0.7969406247138977\n",
      "Epoch: 13 | avg. Train loss 3.839 | avg. Train acc 0.789 | Throughput: 1365.88 images/sec\n",
      "Epoch: 14 | Partition: 0 | Score: 0.7970852851867676\n",
      "Epoch: 14 | Partition: 1 | Score: 0.798535168170929\n",
      "Epoch: 14 | Partition: 2 | Score: 0.8021484613418579\n",
      "Epoch: 14 | Partition: 3 | Score: 0.799511730670929\n",
      "Epoch: 14 | Partition: 4 | Score: 0.8074040412902832\n",
      "Epoch: 14 | avg. Train loss 3.830 | avg. Train acc 0.799 | Throughput: 1378.80 images/sec\n",
      "Epoch: 15 | Partition: 0 | Score: 0.8084401488304138\n",
      "Epoch: 15 | Partition: 1 | Score: 0.8086822628974915\n",
      "Epoch: 15 | Partition: 2 | Score: 0.8099609613418579\n",
      "Epoch: 15 | Partition: 3 | Score: 0.811643123626709\n",
      "Epoch: 15 | Partition: 4 | Score: 0.8121303915977478\n",
      "Epoch: 15 | avg. Train loss 3.821 | avg. Train acc 0.807 | Throughput: 1372.31 images/sec\n",
      "Epoch: 16 | Partition: 0 | Score: 0.8170318007469177\n",
      "Epoch: 16 | Partition: 1 | Score: 0.8080906867980957\n",
      "Epoch: 16 | Partition: 2 | Score: 0.8150038719177246\n",
      "Epoch: 16 | Partition: 3 | Score: 0.8148437738418579\n",
      "Epoch: 16 | Partition: 4 | Score: 0.82421875\n",
      "Epoch: 16 | avg. Train loss 3.813 | avg. Train acc 0.814 | Throughput: 1367.97 images/sec\n",
      "Epoch: 17 | Partition: 0 | Score: 0.820202648639679\n",
      "Epoch: 17 | Partition: 1 | Score: 0.822558581829071\n",
      "Epoch: 17 | Partition: 2 | Score: 0.8199219107627869\n",
      "Epoch: 17 | Partition: 3 | Score: 0.831250011920929\n",
      "Epoch: 17 | Partition: 4 | Score: 0.828950822353363\n",
      "Epoch: 17 | avg. Train loss 3.802 | avg. Train acc 0.824 | Throughput: 1364.71 images/sec\n",
      "Epoch: 18 | Partition: 0 | Score: 0.8204101920127869\n",
      "Epoch: 18 | Partition: 1 | Score: 0.8295232653617859\n",
      "Epoch: 18 | Partition: 2 | Score: 0.8387525677680969\n",
      "Epoch: 18 | Partition: 3 | Score: 0.8263492584228516\n",
      "Epoch: 18 | Partition: 4 | Score: 0.8356229066848755\n",
      "Epoch: 18 | avg. Train loss 3.797 | avg. Train acc 0.829 | Throughput: 1374.95 images/sec\n",
      "Epoch: 19 | Partition: 0 | Score: 0.8321440815925598\n",
      "Epoch: 19 | Partition: 1 | Score: 0.837597668170929\n",
      "Epoch: 19 | Partition: 2 | Score: 0.8355187773704529\n",
      "Epoch: 19 | Partition: 3 | Score: 0.8406385779380798\n",
      "Epoch: 19 | Partition: 4 | Score: 0.8347991108894348\n",
      "Epoch: 19 | avg. Train loss 3.791 | avg. Train acc 0.835 | Throughput: 1375.63 images/sec\n",
      "Epoch: 20 | Partition: 0 | Score: 0.8426613807678223\n",
      "Epoch: 20 | Partition: 1 | Score: 0.8355925679206848\n",
      "Epoch: 20 | Partition: 2 | Score: 0.8396394848823547\n",
      "Epoch: 20 | Partition: 3 | Score: 0.846386730670929\n",
      "Epoch: 20 | Partition: 4 | Score: 0.8454561233520508\n",
      "Epoch: 20 | avg. Train loss 3.784 | avg. Train acc 0.841 | Throughput: 1376.31 images/sec\n",
      "Epoch: 21 | Partition: 0 | Score: 0.846409022808075\n",
      "Epoch: 21 | Partition: 1 | Score: 0.84228515625\n",
      "Epoch: 21 | Partition: 2 | Score: 0.834765613079071\n",
      "Epoch: 21 | Partition: 3 | Score: 0.8539485931396484\n",
      "Epoch: 21 | Partition: 4 | Score: 0.8395918011665344\n",
      "Epoch: 21 | avg. Train loss 3.782 | avg. Train acc 0.843 | Throughput: 1369.98 images/sec\n",
      "Epoch: 22 | Partition: 0 | Score: 0.848187267780304\n",
      "Epoch: 22 | Partition: 1 | Score: 0.8456054925918579\n",
      "Epoch: 22 | Partition: 2 | Score: 0.85107421875\n",
      "Epoch: 22 | Partition: 3 | Score: 0.8395361304283142\n",
      "Epoch: 22 | Partition: 4 | Score: 0.853661060333252\n",
      "Epoch: 22 | avg. Train loss 3.777 | avg. Train acc 0.848 | Throughput: 1354.02 images/sec\n",
      "Epoch: 23 | Partition: 0 | Score: 0.8505744934082031\n",
      "Epoch: 23 | Partition: 1 | Score: 0.8501953482627869\n",
      "Epoch: 23 | Partition: 2 | Score: 0.8476980328559875\n",
      "Epoch: 23 | Partition: 3 | Score: 0.8553305864334106\n",
      "Epoch: 23 | Partition: 4 | Score: 0.8495678305625916\n",
      "Epoch: 23 | avg. Train loss 3.774 | avg. Train acc 0.850 | Throughput: 1313.56 images/sec\n",
      "Epoch: 24 | Partition: 0 | Score: 0.8533668518066406\n",
      "Epoch: 24 | Partition: 1 | Score: 0.85205078125\n",
      "Epoch: 24 | Partition: 2 | Score: 0.8519531488418579\n",
      "Epoch: 24 | Partition: 3 | Score: 0.8568668365478516\n",
      "Epoch: 24 | Partition: 4 | Score: 0.8524414300918579\n",
      "Epoch: 24 | avg. Train loss 3.772 | avg. Train acc 0.853 | Throughput: 1359.48 images/sec\n",
      "Epoch: 25 | Partition: 0 | Score: 0.8489829301834106\n",
      "Epoch: 25 | Partition: 1 | Score: 0.8602747917175293\n",
      "Epoch: 25 | Partition: 2 | Score: 0.8612304925918579\n",
      "Epoch: 25 | Partition: 3 | Score: 0.8541918992996216\n",
      "Epoch: 25 | Partition: 4 | Score: 0.8584637641906738\n",
      "Epoch: 25 | avg. Train loss 3.768 | avg. Train acc 0.855 | Throughput: 1356.43 images/sec\n",
      "Epoch: 26 | Partition: 0 | Score: 0.8614862561225891\n",
      "Epoch: 26 | Partition: 1 | Score: 0.8603559732437134\n",
      "Epoch: 26 | Partition: 2 | Score: 0.8580609560012817\n",
      "Epoch: 26 | Partition: 3 | Score: 0.849316418170929\n",
      "Epoch: 26 | Partition: 4 | Score: 0.8595226407051086\n",
      "Epoch: 26 | avg. Train loss 3.767 | avg. Train acc 0.858 | Throughput: 1361.03 images/sec\n",
      "Epoch: 27 | Partition: 0 | Score: 0.8613781929016113\n",
      "Epoch: 27 | Partition: 1 | Score: 0.8624741435050964\n",
      "Epoch: 27 | Partition: 2 | Score: 0.8568359613418579\n",
      "Epoch: 27 | Partition: 3 | Score: 0.857421875\n",
      "Epoch: 27 | Partition: 4 | Score: 0.8604019284248352\n",
      "Epoch: 27 | avg. Train loss 3.764 | avg. Train acc 0.859 | Throughput: 1356.54 images/sec\n",
      "Epoch: 28 | Partition: 0 | Score: 0.855175793170929\n",
      "Epoch: 28 | Partition: 1 | Score: 0.8642176985740662\n",
      "Epoch: 28 | Partition: 2 | Score: 0.8663086295127869\n",
      "Epoch: 28 | Partition: 3 | Score: 0.865429699420929\n",
      "Epoch: 28 | Partition: 4 | Score: 0.863198459148407\n",
      "Epoch: 28 | avg. Train loss 3.765 | avg. Train acc 0.860 | Throughput: 1339.12 images/sec\n",
      "Epoch: 29 | Partition: 0 | Score: 0.8640540242195129\n",
      "Epoch: 29 | Partition: 1 | Score: 0.853320300579071\n",
      "Epoch: 29 | Partition: 2 | Score: 0.8672454953193665\n",
      "Epoch: 29 | Partition: 3 | Score: 0.870800793170929\n",
      "Epoch: 29 | Partition: 4 | Score: 0.8645452857017517\n",
      "Epoch: 29 | avg. Train loss 3.761 | avg. Train acc 0.863 | Throughput: 1335.44 images/sec\n",
      "Epoch: 30 | Partition: 0 | Score: 0.861657440662384\n",
      "Epoch: 30 | Partition: 1 | Score: 0.859082043170929\n",
      "Epoch: 30 | Partition: 2 | Score: 0.8697181940078735\n",
      "Epoch: 30 | Partition: 3 | Score: 0.870800793170929\n",
      "Epoch: 30 | Partition: 4 | Score: 0.867382824420929\n",
      "Epoch: 30 | avg. Train loss 3.759 | avg. Train acc 0.865 | Throughput: 1320.91 images/sec\n",
      "Epoch: 31 | Partition: 0 | Score: 0.8595039248466492\n",
      "Epoch: 31 | Partition: 1 | Score: 0.8658203482627869\n",
      "Epoch: 31 | Partition: 2 | Score: 0.8662140965461731\n",
      "Epoch: 31 | Partition: 3 | Score: 0.8728401064872742\n",
      "Epoch: 31 | Partition: 4 | Score: 0.868847668170929\n",
      "Epoch: 31 | avg. Train loss 3.758 | avg. Train acc 0.867 | Throughput: 1348.64 images/sec\n",
      "Epoch: 32 | Partition: 0 | Score: 0.8634613156318665\n",
      "Epoch: 32 | Partition: 1 | Score: 0.87255859375\n",
      "Epoch: 32 | Partition: 2 | Score: 0.868457019329071\n",
      "Epoch: 32 | Partition: 3 | Score: 0.8703640103340149\n",
      "Epoch: 32 | Partition: 4 | Score: 0.8653754591941833\n",
      "Epoch: 32 | avg. Train loss 3.757 | avg. Train acc 0.868 | Throughput: 1317.13 images/sec\n",
      "Epoch: 33 | Partition: 0 | Score: 0.8658203482627869\n",
      "Epoch: 33 | Partition: 1 | Score: 0.874316394329071\n",
      "Epoch: 33 | Partition: 2 | Score: 0.866406261920929\n",
      "Epoch: 33 | Partition: 3 | Score: 0.8741856813430786\n",
      "Epoch: 33 | Partition: 4 | Score: 0.868678092956543\n",
      "Epoch: 33 | avg. Train loss 3.753 | avg. Train acc 0.870 | Throughput: 1340.73 images/sec\n",
      "Epoch: 34 | Partition: 0 | Score: 0.8671875\n",
      "Epoch: 34 | Partition: 1 | Score: 0.8682617545127869\n",
      "Epoch: 34 | Partition: 2 | Score: 0.8694645166397095\n",
      "Epoch: 34 | Partition: 3 | Score: 0.8717524409294128\n",
      "Epoch: 34 | Partition: 4 | Score: 0.8781251311302185\n",
      "Epoch: 34 | avg. Train loss 3.753 | avg. Train acc 0.870 | Throughput: 1276.84 images/sec\n",
      "Epoch: 35 | Partition: 0 | Score: 0.876171886920929\n",
      "Epoch: 35 | Partition: 1 | Score: 0.8677734732627869\n",
      "Epoch: 35 | Partition: 2 | Score: 0.878613293170929\n",
      "Epoch: 35 | Partition: 3 | Score: 0.87939453125\n",
      "Epoch: 35 | Partition: 4 | Score: 0.8679303526878357\n",
      "Epoch: 35 | avg. Train loss 3.751 | avg. Train acc 0.872 | Throughput: 1352.35 images/sec\n",
      "Epoch: 36 | Partition: 0 | Score: 0.8710365295410156\n",
      "Epoch: 36 | Partition: 1 | Score: 0.8692192435264587\n",
      "Epoch: 36 | Partition: 2 | Score: 0.8745018839836121\n",
      "Epoch: 36 | Partition: 3 | Score: 0.874607503414154\n",
      "Epoch: 36 | Partition: 4 | Score: 0.8816066980361938\n",
      "Epoch: 36 | avg. Train loss 3.751 | avg. Train acc 0.873 | Throughput: 1348.84 images/sec\n",
      "Epoch: 37 | Partition: 0 | Score: 0.866622269153595\n",
      "Epoch: 37 | Partition: 1 | Score: 0.8782558441162109\n",
      "Epoch: 37 | Partition: 2 | Score: 0.877636730670929\n",
      "Epoch: 37 | Partition: 3 | Score: 0.8756036758422852\n",
      "Epoch: 37 | Partition: 4 | Score: 0.8763702511787415\n",
      "Epoch: 37 | avg. Train loss 3.751 | avg. Train acc 0.873 | Throughput: 1344.59 images/sec\n",
      "Epoch: 38 | Partition: 0 | Score: 0.876269519329071\n",
      "Epoch: 38 | Partition: 1 | Score: 0.8792991638183594\n",
      "Epoch: 38 | Partition: 2 | Score: 0.8762041330337524\n",
      "Epoch: 38 | Partition: 3 | Score: 0.8700195550918579\n",
      "Epoch: 38 | Partition: 4 | Score: 0.8807617425918579\n",
      "Epoch: 38 | avg. Train loss 3.747 | avg. Train acc 0.876 | Throughput: 1348.99 images/sec\n",
      "Epoch: 39 | Partition: 0 | Score: 0.8744603395462036\n",
      "Epoch: 39 | Partition: 1 | Score: 0.8781177401542664\n",
      "Epoch: 39 | Partition: 2 | Score: 0.88037109375\n",
      "Epoch: 39 | Partition: 3 | Score: 0.8729492425918579\n",
      "Epoch: 39 | Partition: 4 | Score: 0.881054699420929\n",
      "Epoch: 39 | avg. Train loss 3.746 | avg. Train acc 0.877 | Throughput: 1374.43 images/sec\n",
      "Epoch: 40 | Partition: 0 | Score: 0.877077043056488\n",
      "Epoch: 40 | Partition: 1 | Score: 0.8728429675102234\n",
      "Epoch: 40 | Partition: 2 | Score: 0.87451171875\n",
      "Epoch: 40 | Partition: 3 | Score: 0.8830403685569763\n",
      "Epoch: 40 | Partition: 4 | Score: 0.880175769329071\n",
      "Epoch: 40 | avg. Train loss 3.746 | avg. Train acc 0.878 | Throughput: 1380.72 images/sec\n",
      "Epoch: 41 | Partition: 0 | Score: 0.8725746273994446\n",
      "Epoch: 41 | Partition: 1 | Score: 0.877323567867279\n",
      "Epoch: 41 | Partition: 2 | Score: 0.8797246813774109\n",
      "Epoch: 41 | Partition: 3 | Score: 0.881152331829071\n",
      "Epoch: 41 | Partition: 4 | Score: 0.8861560225486755\n",
      "Epoch: 41 | avg. Train loss 3.744 | avg. Train acc 0.879 | Throughput: 1378.74 images/sec\n",
      "Epoch: 42 | Partition: 0 | Score: 0.8783203363418579\n",
      "Epoch: 42 | Partition: 1 | Score: 0.8763973712921143\n",
      "Epoch: 42 | Partition: 2 | Score: 0.8797735571861267\n",
      "Epoch: 42 | Partition: 3 | Score: 0.8790039420127869\n",
      "Epoch: 42 | Partition: 4 | Score: 0.8871148228645325\n",
      "Epoch: 42 | avg. Train loss 3.743 | avg. Train acc 0.880 | Throughput: 1380.19 images/sec\n",
      "Epoch: 43 | Partition: 0 | Score: 0.8846394419670105\n",
      "Epoch: 43 | Partition: 1 | Score: 0.8769316673278809\n",
      "Epoch: 43 | Partition: 2 | Score: 0.8746094107627869\n",
      "Epoch: 43 | Partition: 3 | Score: 0.883105456829071\n",
      "Epoch: 43 | Partition: 4 | Score: 0.8828372955322266\n",
      "Epoch: 43 | avg. Train loss 3.741 | avg. Train acc 0.881 | Throughput: 1381.30 images/sec\n",
      "Epoch: 44 | Partition: 0 | Score: 0.8732418417930603\n",
      "Epoch: 44 | Partition: 1 | Score: 0.8900390863418579\n",
      "Epoch: 44 | Partition: 2 | Score: 0.8768936991691589\n",
      "Epoch: 44 | Partition: 3 | Score: 0.8877870440483093\n",
      "Epoch: 44 | Partition: 4 | Score: 0.8797851800918579\n",
      "Epoch: 44 | avg. Train loss 3.742 | avg. Train acc 0.882 | Throughput: 1381.90 images/sec\n",
      "Epoch: 45 | Partition: 0 | Score: 0.8880907297134399\n",
      "Epoch: 45 | Partition: 1 | Score: 0.8868164420127869\n",
      "Epoch: 45 | Partition: 2 | Score: 0.8761407732963562\n",
      "Epoch: 45 | Partition: 3 | Score: 0.8874818682670593\n",
      "Epoch: 45 | Partition: 4 | Score: 0.8810747265815735\n",
      "Epoch: 45 | avg. Train loss 3.741 | avg. Train acc 0.882 | Throughput: 1381.32 images/sec\n",
      "Epoch: 46 | Partition: 0 | Score: 0.8822536468505859\n",
      "Epoch: 46 | Partition: 1 | Score: 0.8802447319030762\n",
      "Epoch: 46 | Partition: 2 | Score: 0.8848633170127869\n",
      "Epoch: 46 | Partition: 3 | Score: 0.8821016550064087\n",
      "Epoch: 46 | Partition: 4 | Score: 0.8858398795127869\n",
      "Epoch: 46 | avg. Train loss 3.742 | avg. Train acc 0.882 | Throughput: 1379.97 images/sec\n",
      "Epoch: 47 | Partition: 0 | Score: 0.881054699420929\n",
      "Epoch: 47 | Partition: 1 | Score: 0.8875808715820312\n",
      "Epoch: 47 | Partition: 2 | Score: 0.8876258730888367\n",
      "Epoch: 47 | Partition: 3 | Score: 0.8839840888977051\n",
      "Epoch: 47 | Partition: 4 | Score: 0.8756095170974731\n",
      "Epoch: 47 | avg. Train loss 3.739 | avg. Train acc 0.884 | Throughput: 1361.58 images/sec\n",
      "Epoch: 48 | Partition: 0 | Score: 0.8813645243644714\n",
      "Epoch: 48 | Partition: 1 | Score: 0.8916015625\n",
      "Epoch: 48 | Partition: 2 | Score: 0.8818318247795105\n",
      "Epoch: 48 | Partition: 3 | Score: 0.8810670971870422\n",
      "Epoch: 48 | Partition: 4 | Score: 0.8881950378417969\n",
      "Epoch: 48 | avg. Train loss 3.738 | avg. Train acc 0.885 | Throughput: 1364.94 images/sec\n",
      "Epoch: 49 | Partition: 0 | Score: 0.8873893022537231\n",
      "Epoch: 49 | Partition: 1 | Score: 0.8930060267448425\n",
      "Epoch: 49 | Partition: 2 | Score: 0.8866211175918579\n",
      "Epoch: 49 | Partition: 3 | Score: 0.8822104334831238\n",
      "Epoch: 49 | Partition: 4 | Score: 0.8829809427261353\n",
      "Epoch: 49 | avg. Train loss 3.739 | avg. Train acc 0.884 | Throughput: 1354.65 images/sec\n",
      "Epoch: 50 | Partition: 0 | Score: 0.879687488079071\n",
      "Epoch: 50 | Partition: 1 | Score: 0.8873047232627869\n",
      "Epoch: 50 | Partition: 2 | Score: 0.8866526484489441\n",
      "Epoch: 50 | Partition: 3 | Score: 0.8905269503593445\n",
      "Epoch: 50 | Partition: 4 | Score: 0.8861479163169861\n",
      "Epoch: 50 | avg. Train loss 3.737 | avg. Train acc 0.886 | Throughput: 1346.27 images/sec\n"
     ]
    }
   ],
   "source": [
    "import trainer\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "epochs = 50\n",
    "optimizer = optim.Adam(learning_rate=0.0001)\n",
    "n_partitions = 5\n",
    "\n",
    "def get_partitions(partition_start, partition_num):\n",
    "    ranges = [i for i in range(partition_num)]\n",
    "    ranges.remove(partition_start)\n",
    "    return partition_start, ranges\n",
    "\n",
    "validation_scores = {k: [] for k in range(n_partitions) }\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_epoch_loss = []\n",
    "    train_epoch_accuracy = []\n",
    "    train_epoch_throughput = []\n",
    "    shuffled_train_data = train_data.shuffle()\n",
    "    for partition_no in range(n_partitions):\n",
    "        # get validation partition and train partitions\n",
    "        validation_partition_idx, train_partitions = get_partitions(partition_no, n_partitions)\n",
    "\n",
    "        # train on all partitions except the validation partition\n",
    "        for train_partition_idx in train_partitions:\n",
    "            train_partition = shuffled_train_data.partition(n_partitions, train_partition_idx)\n",
    "            data = get_streamed_data(data=train_partition, batch_size=256, shuffled=True)\n",
    "            train_loss, train_acc, throughput = trainer.train_epoch(model, data, optimizer, epoch, verbose=False)\n",
    "\n",
    "            train_epoch_loss.append(train_loss.item())\n",
    "            train_epoch_accuracy.append(train_acc.item())\n",
    "            train_epoch_throughput.append(throughput.item())\n",
    "        validation_partition = shuffled_train_data.partition(n_partitions, validation_partition_idx)\n",
    "        validation_data = get_streamed_data(data=validation_partition, batch_size=256, shuffled=False)\n",
    "        validation_score = trainer.test_epoch(model, validation_data, epoch).item()\n",
    "        validation_scores[partition_no].append(validation_score)\n",
    "        \n",
    "        print(\" | \".join((f\"Epoch: {epoch+1}\", f\"Partition: {partition_no}\", f\"Score: {validation_score}\")))\n",
    "\n",
    "    train_epoch_loss = mx.mean(mx.array(train_epoch_loss))\n",
    "    train_epoch_accuracy = mx.mean(mx.array(train_epoch_accuracy))\n",
    "    train_epoch_throughput = mx.mean(mx.array(train_epoch_throughput))\n",
    "    print(\" | \".join(\n",
    "                (\n",
    "                    f\"Epoch: {epoch+1}\",\n",
    "                    f\"avg. Train loss {train_epoch_loss.item():.3f}\",\n",
    "                    f\"avg. Train acc {train_epoch_accuracy.item():.3f}\",\n",
    "                    f\"Throughput: {train_epoch_throughput.item():.2f} images/sec\",\n",
    "                )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cefcd0-1b1e-4ed9-b2fb-c41e9ec4080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4562159620317154\n",
      "Recall: 0.4623\n",
      "F1 Score: 0.45719586228928\n"
     ]
    }
   ],
   "source": [
    "# get precision, recall, and f1-score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "test_stream = get_streamed_data(data=test_data, batch_size=256, shuffled=False)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "model.eval()\n",
    "for batch in test_stream:\n",
    "    X, y = batch[\"image\"], batch[\"label\"]\n",
    "    X, y = mx.array(X), mx.array(y)\n",
    "    logits = model(X)\n",
    "    prediction = mx.argmax(mx.softmax(logits), axis=1)\n",
    "    y_true = y_true + y.tolist()\n",
    "    y_pred = y_pred + prediction.tolist()\n",
    "    \n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average=\"weighted\")\n",
    "recall = recall_score(y_true, y_pred, average=\"weighted\")\n",
    "f1 = f1_score(y_true, y_pred, average=\"weighted\")\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c30d3da-b189-444f-800d-c97acc6d7de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
